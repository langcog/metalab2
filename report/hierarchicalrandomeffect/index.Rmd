---
title: "Hierarchical Random Effects in Meta-Analyses: Do they change stuff?"
author: "Sho Tsuji and Christina Bergmann"
date: "`r Sys.Date()`"
summary: "Here we explore whether and how accounting for this possible correlation affects both a random effects base model and a moderator analysis."
output: 
  blogdown::html_page:
    self_contained: false
    toc: true
    highlight: tango
    fig.width: 8
    fig.height: 5
---
  
# Introduction
```{r, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE, cache = TRUE)
#ggplot2::theme_set(langcog::theme_mikabr(base_family = "Ubuntu"))
library(metafor)
library(dplyr)
library(tidyr)
library(ggplot2)
library(stringr)
library(purrr)
library(langcog)
```

Each effect size is nested within an experiment which is in turn nested within a paper (this includes unpublished reports, theses, and the likes). It can be assumed that effect sizes  within these nested structures are not independent. Here we explore whether and how accounting for this possible correlation affects both a random effects base model and a moderator analysis. As example we chose InWordDB. 


# Base Model

Standard random effects model, no moderators. First we run the model without accounting for any hierarchical structure (as reported in the publication by Bergmann & Cristia 2015; note that differences in effect size estimation are due to an updated dataset here that also includes nonnative studies, as compared to the paper).

```{r Data}
library(here)
load(here("shinyapps", "site_data", "Rdata", "metalab.Rdata"))
inworddb <- droplevels(metalab_data[metalab_data$short_name=="inworddb", ])

StandardMod <- rma(g_calc, g_var_calc, data = inworddb)
summary(StandardMod)
```

## Two Level Model: Paper

We first add a level for the paper a given effect size was reported in. These effect sizes presumably stem from a batch of studies that were conducted in the same lab in a very similar fashion and by the same set of experimenters, introducing possible correlations. 

```{r RandPerPaper}

PerPaperMod <- rma.mv(g_calc, g_var_calc, random = ~ 1 | short_cite, data = inworddb)
summary(PerPaperMod)
```

## Three Level Model: Paper and Experiment

Nested within paper, we introduce a level for experiment number. Experiments can report several effect sizes, for example when infants are run in conditions; slight variations of the same study which are presumed to be even more similar than effect sizes within a paper. 
A caveat is that conventions on what counts as experiment and what counts as conditions within an experiment might differ across papers. 

```{r RandPerExpAndPaper}

PerExpPaperMod <- rma.mv(g_calc, g_var_calc, random = ~ factor(expt_num) |  short_cite, data = inworddb)
summary(PerExpPaperMod)
```

To summarize, all these models differ in their effect size estimates, but do not change the statistical outcome. The effect remains small but significantly above 0. Adding the level of experiment number did not dramatically change the result.

# Moderator Model from the Paper

```{r AgeSimple}
#Centering mean age
inworddb$ageC <- inworddb$mean_age-mean(inworddb$mean_age)

StandardMod <- rma(g_calc, g_var_calc, mod = ageC, data = inworddb)
summary(StandardMod)
```

## Two Level Model: Paper

```{r AgePerPaper}

PerPaperMod <- rma.mv(g_calc, g_var_calc, mod = ageC, random = ~ 1 | short_cite, data = inworddb)
summary(PerPaperMod)
```


## Three Level Model: Paper and Experiment

```{r AgePerExpAndPaper}

PerExpPaperMod <- rma.mv(g_calc, g_var_calc, mod = ageC, random = ~ factor(expt_num) |  short_cite, data = inworddb)
summary(PerExpPaperMod)
```

To summarize, introducing hierarchical structure changed the outcome for the moderator test. Age (centered) now has a small, but significant, effect on effect sizes. This is not the case when ignoring the nested structure of effect sizes. 
This result mirrors the reported analyses in Bergmann & Cristia (2015) that there is a small, positive effect of age when only considering papers which test at least two age groups in the same set-up. 
